{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_advanced_nn(input_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(128, activation=\"relu\", input_shape=input_shape))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.4))\n",
    "\n",
    "    model.add(layers.Dense(64, activation=\"relu\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.4))\n",
    "\n",
    "    model.add(layers.Dense(32, activation=\"relu\"))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.4))\n",
    "\n",
    "    model.add(layers.Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_path = \"/kaggle/input/isic-2024-challenge/train-metadata.csv\"\n",
    "test_metadata_path = \"/kaggle/input/isic-2024-challenge/test-metadata.csv\"\n",
    "\n",
    "train_metadata = pd.read_csv(train_metadata_path)\n",
    "test_metadata = pd.read_csv(test_metadata_path)\n",
    "\n",
    "train_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for cols. with missing values.\n",
    "missing_values = train_metadata.isnull().sum()\n",
    "print(\"Missing Values=\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = [\n",
    "    \"lesion_id\",\n",
    "    \"iddx_2\",\n",
    "    \"iddx_3\",\n",
    "    \"iddx_4\",\n",
    "    \"iddx_5\",\n",
    "    \"mel_mitotic_index\",\n",
    "    \"mel_thick_mm\",\n",
    "]\n",
    "train_metadata_cleaned = train_metadata.drop(columns=columns_to_remove, errors=\"ignore\")\n",
    "train_metadata_cleaned_no_nulls = train_metadata_cleaned.dropna()\n",
    "train_metadata_cleaned_no_nulls[\"target\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority = train_metadata_cleaned_no_nulls[\n",
    "    train_metadata_cleaned_no_nulls[\"target\"] == 0\n",
    "]\n",
    "minority = train_metadata_cleaned_no_nulls[\n",
    "    train_metadata_cleaned_no_nulls[\"target\"] == 1\n",
    "]\n",
    "majority_class_downsample = resample(\n",
    "    majority, replace=False, n_samples=len(minority), random_state=42\n",
    ")\n",
    "train_metadata_balanced = pd.concat([majority_class_downsample, minority])\n",
    "\n",
    "\n",
    "print(\"Shpareee after balancing classes: \", train_metadata_balanced.shape)\n",
    "print(\n",
    "    \"Class Dist. after balancing: \\n\", train_metadata_balanced[\"target\"].value_counts()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_balanced[\"sex\"] = train_metadata_balanced[\"sex\"].map(\n",
    "    {\"male\": 1, \"female\": 0}\n",
    ")\n",
    "\n",
    "anatom_site_mapping = {\n",
    "    \"posterior torso\": 1,\n",
    "    \"lower extremity\": 2,\n",
    "    \"anterior torso\": 3,\n",
    "    \"upper extremity\": 4,\n",
    "    \"head/neck\": 5,\n",
    "}\n",
    "\n",
    "tbp_lv_location_mapping = {\n",
    "    \"Torso Front Top Half\": 1,\n",
    "    \"Torso Back Top Third\": 2,\n",
    "    \"Head & Neck\": 3,\n",
    "    \"Torso Back Middle Third\": 4,\n",
    "    \"Left Leg - Lower\": 5,\n",
    "    \"Right Leg - Lower\": 6,\n",
    "    \"Torso Front Bottom Half\": 7,\n",
    "    \"Left Arm - Upper\": 8,\n",
    "    \"Left Leg - Upper\": 9,\n",
    "    \"Right Arm - Upper\": 10,\n",
    "    \"Right Leg - Upper\": 11,\n",
    "    \"Left Arm - Lower\": 12,\n",
    "    \"Right Arm - Lower\": 13,\n",
    "    \"Torso Back Bottom Third\": 14,\n",
    "    \"Left Leg\": 15,\n",
    "    \"Right Leg\": 16,\n",
    "    \"Left Arm\": 17,\n",
    "    \"Right Arm\": 18,\n",
    "}\n",
    "\n",
    "\n",
    "tbp_lv_location_simple_mapping = {\n",
    "    \"Torso Back\": 1,\n",
    "    \"Torso Front\": 2,\n",
    "    \"Left Leg\": 3,\n",
    "    \"Head & Neck\": 4,\n",
    "    \"Right Leg\": 5,\n",
    "    \"Left Arm\": 6,\n",
    "    \"Right Arm\": 7,\n",
    "}\n",
    "\n",
    "\n",
    "train_metadata_balanced[\"anatom_site_general\"] = train_metadata_balanced[\n",
    "    \"anatom_site_general\"\n",
    "].apply(lambda x: anatom_site_mapping.get(x, 0))\n",
    "\n",
    "train_metadata_balanced[\"tbp_lv_location\"] = train_metadata_balanced[\n",
    "    \"tbp_lv_location\"\n",
    "].apply(lambda x: tbp_lv_location_mapping.get(x, 0))\n",
    "\n",
    "train_metadata_balanced[\"tbp_lv_location_simple\"] = train_metadata_balanced[\n",
    "    \"tbp_lv_location_simple\"\n",
    "].apply(lambda x: tbp_lv_location_simple_mapping.get(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_balanced.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metadata_balanced[\"age_sex_interaction\"] = (\n",
    "    train_metadata_balanced[\"age_approx\"] * train_metadata_balanced[\"sex\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_metadata_balanced.drop(\n",
    "    columns=[\n",
    "        \"isic_id\",\n",
    "        \"target\",\n",
    "        \"patient_id\",\n",
    "        \"image_type\",\n",
    "        \"tbp_tile_type\",\n",
    "        \"attribution\",\n",
    "        \"copyright_license\",\n",
    "        \"iddx_full\",\n",
    "        \"iddx_1\",\n",
    "        \"tbp_lv_dnn_lesion_confidence\",\n",
    "    ]\n",
    ")\n",
    "y = train_metadata_balanced[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    .batch(64)\n",
    "    .shuffle(buffer_size=1024)\n",
    ")\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (39,)\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
    ")\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\", factor=0.5, patience=3\n",
    ")\n",
    "model = build_advanced_nn(input_shape)\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, val_accuracy = model.evaluate(val_dataset)\n",
    "print(f\"Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "lgb_model = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, max_depth=6)\n",
    "lgb_model.fit(X_train, y_train)\n",
    "\n",
    "base_learners = [(\"xgb\", xgb_model), (\"lgb\", lgb_model)]\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=base_learners, final_estimator=LogisticRegression()\n",
    ")\n",
    "stacking_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network evaluation\n",
    "val_loss, val_accuracy = model.evaluate(val_dataset)\n",
    "print(f\"Validation Accuracy (NN): {val_accuracy:.4f}\")\n",
    "\n",
    "# XGBoost evaluation\n",
    "y_val_pred_xgb = xgb_model.predict_proba(X_val)[:, 1]\n",
    "roc_auc_xgb = roc_auc_score(y_val, y_val_pred_xgb)\n",
    "print(f\"XGBoost ROC AUC Score: {roc_auc_xgb:.4f}\")\n",
    "\n",
    "# LightGBM evaluation\n",
    "y_val_pred_lgb = lgb_model.predict_proba(X_val)[:, 1]\n",
    "roc_auc_lgb = roc_auc_score(y_val, y_val_pred_lgb)\n",
    "print(f\"LightGBM ROC AUC Score: {roc_auc_lgb:.4f}\")\n",
    "\n",
    "# Stacking model evaluation\n",
    "y_val_pred_stacking = stacking_clf.predict_proba(X_val)[:, 1]\n",
    "roc_auc_stacking = roc_auc_score(y_val, y_val_pred_stacking)\n",
    "print(f\"Stacking ROC AUC Score: {roc_auc_stacking:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_metadata_cleaned = test_metadata.drop(columns=columns_to_remove, errors=\"ignore\")\n",
    "test_metadata_cleaned[\"sex\"] = test_metadata_cleaned[\"sex\"].map(\n",
    "    {\"male\": 1, \"female\": 0}\n",
    ")\n",
    "test_metadata_cleaned[\"anatom_site_general\"] = test_metadata_cleaned[\n",
    "    \"anatom_site_general\"\n",
    "].apply(lambda x: anatom_site_mapping.get(x, 0))\n",
    "test_metadata_cleaned[\"tbp_lv_location\"] = test_metadata_cleaned[\n",
    "    \"tbp_lv_location\"\n",
    "].apply(lambda x: tbp_lv_location_mapping.get(x, 0))\n",
    "test_metadata_cleaned[\"tbp_lv_location_simple\"] = test_metadata_cleaned[\n",
    "    \"tbp_lv_location_simple\"\n",
    "].apply(lambda x: tbp_lv_location_simple_mapping.get(x, 0))\n",
    "\n",
    "test_metadata_cleaned[\"age_sex_interaction\"] = (\n",
    "    test_metadata_cleaned[\"age_approx\"] * test_metadata_cleaned[\"sex\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_metadata_cleaned[X.columns]  # Align columns with training set\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = stacking_clf.predict_proba(X_test_scaled)[:, 1]\n",
    "test_predicted_labels = (test_predictions > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    {\"isic_id\": test_metadata[\"isic_id\"], \"target\": test_predicted_labels}\n",
    ")\n",
    "submission.to_csv(\n",
    "    \"/kaggle/working/submission.csv\",\n",
    "    index=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PracConda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
